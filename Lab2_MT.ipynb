{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_MT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLMCpkVezMGT7JwJRruPaq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bucuram/machine-translation-labs/blob/main/Lab2_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjiNn4XDtESN"
      },
      "source": [
        "##Overview of Approaches to MT\n",
        "\n",
        "### Open NMT frameworks\n",
        "* [Moses](http://www.statmt.org/moses/https://aclanthology.org/P07-2045.pdf). Paper: [Moses: Open Source Toolkit for Statistical Machine Translation](https://aclanthology.org/P07-2045.pdf). C++\n",
        "\n",
        "* [OpenNMT](https://github.com/OpenNMT/OpenNMT-py). Paper: [OpenNMT: Open-Source Toolkit for Neural Machine Translation](https://aclanthology.org/P17-4012.pdf). PyTorch / TensorFlow. Developed by Harvard NLP,  SYSTRAN\n",
        "* [Marian](https://marian-nmt.github.io/). Paper: [Marian: Fast Neural Machine Translation in C++](https://aclanthology.org/P18-4020.pdf). C++. Developed by Microsoft Translator\n",
        "* [Fairseq](https://github.com/pytorch/fairseq). Paper: [https://aclanthology.org/N19-4009.pdf](https://aclanthology.org/N19-4009.pdf). PyTorch. Developed by Facebook AI\n",
        "* [Nematus](https://github.com/EdinburghNLP/nematus). Paper: [Nematus: a Toolkit for Neural Machine Translation](https://aclanthology.org/E17-3017.pdf). TensorFlow. Developed by Edinburgh NLP\n",
        "* [Sockeye](https://github.com/awslabs/sockeye). Paper: [SOCKEYE 2:A Toolkit for Neural Machine Translation](https://aclanthology.org/2020.eamt-1.50.pdf). MXNet. Developed by Amazon\n",
        "* [JoeyNMT](https://github.com/joeynmt/joeynmt). Paper: [Joey NMT: A Minimalist NMT Toolkit for Novices](https://aclanthology.org/D19-3019v1.pdf). PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efi_dqwm-8fb"
      },
      "source": [
        "###Exploring the fairseq framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSTgKz3cBlXa"
      },
      "source": [
        "Installing fairseq, mosestokenizer and tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw6BQ2aELpF4",
        "outputId": "ba15ce04-0b78-4720-cdc2-6559c91cffa3"
      },
      "source": [
        "!pip install fairseq "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairseq in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.9.0+cu111)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq) (2.0.0)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.1.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.14.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq) (4.62.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.29.24)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from fairseq) (0.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.3.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq) (2.20)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (5.2.2)\n",
            "Requirement already satisfied: omegaconf==2.1.* in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (2.1.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf==2.1.*->hydra-core->fairseq) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKzw-dpE_Kaz"
      },
      "source": [
        "###Downloading the data\n",
        "\n",
        "We will use the Europarl parallel corpus https://www.statmt.org/europarl/. It contains translations of parliament proceedings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkcDrW04_JsV",
        "outputId": "33c07aea-bd47-472a-d047-06eb1d600093"
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Europarl/v8/moses/en-ro.txt.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-20 19:30:24--  https://object.pouta.csc.fi/OPUS-Europarl/v8/moses/en-ro.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39495951 (38M) [application/zip]\n",
            "Saving to: ‘en-ro.txt.zip.1’\n",
            "\n",
            "en-ro.txt.zip.1     100%[===================>]  37.67M  11.3MB/s    in 3.6s    \n",
            "\n",
            "2021-10-20 19:30:28 (10.5 MB/s) - ‘en-ro.txt.zip.1’ saved [39495951/39495951]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i-IR3LxATiO"
      },
      "source": [
        "!mkdir data\n",
        "!mv en-ro.txt.zip data/en-ro.txt.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTXeXL-cA4zA",
        "outputId": "7edca2ea-e878-4c42-c1dc-97868a98b2fb"
      },
      "source": [
        "!unzip data/en-ro.txt.zip\n",
        "!rm data/Europarl.en-ro.xml"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "Archive:  en-ro.txt.zip\n",
            "  inflating: README                  \n",
            "  inflating: LICENSE                 \n",
            "  inflating: Europarl.en-ro.en       \n",
            "  inflating: Europarl.en-ro.ro       \n",
            "  inflating: Europarl.en-ro.xml      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK7Z8DmUBt57"
      },
      "source": [
        "The size of files in lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaSl8wlGB5NX",
        "outputId": "f210bddf-1b65-4541-8419-a05a495c1047"
      },
      "source": [
        "!wc -l data/Europarl*"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   400356 Europarl.en-ro.en\n",
            "   400356 Europarl.en-ro.ro\n",
            "   800712 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyBhJ2kBChqY"
      },
      "source": [
        "We shuffle and merge the source and target files horizontally (each line of the resulting file will contain a source line and a target line, separated by a tab)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFD7dbjdCj1c"
      },
      "source": [
        "!paste Europarl.en-ro.ro Europarl.en-ro.en | shuf > shuf-Europarl.en-ro.both"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIXoEMLLC2gs",
        "outputId": "5f2db98f-626a-468c-ded5-1985d3a29956"
      },
      "source": [
        "with open('data/shuf-Europarl.en-ro.both', 'r', encoding='utf8') as fh:\n",
        "    for i in range(5):\n",
        "        et_sentence, en_sentence = fh.readline().strip().split('\\t')\n",
        "        print('RO: {}\\nEN: {}\\n'.format(et_sentence, en_sentence))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RO: Aş dori să îi mulţumesc în mod deosebit raportoarei, dna Lynne, pentru munca excelentă în întocmirea propunerii de rezoluţie referitoare la propunerea Comisiei şi pentru eforturile sale, de-a lungul mai multor ani, în vederea îmbunătăţirii sănătăţii şi siguranţei la locul de muncă pentru lucrătorii din sectorul spitalicesc şi al asistenţei medicale.\n",
            "EN: In particular I want to thank the rapporteur, Mrs Lynne, for her excellent work in drawing up the motion for a resolution on the Commission's proposal and for her efforts over a number of years to improve health and safety at work for workers in the hospital and healthcare sector.\n",
            "\n",
            "RO: Acestea ridică între noi bariere inutile pe care, la urma urmelor, le-am demontat timp de decenii şi aşa trebuie să facem şi pe viitor.\n",
            "EN: These build unnecessary walls between us which, after all, we have been dismantling for decades, and that is what the future is about.\n",
            "\n",
            "RO: Salut propunerea de prevederi mai solide care încearcă să prevină transporturile ilegale ale acestor deșeuri și să completeze lacunele din legislație.\n",
            "EN: I welcome the proposal of stronger provisions which seek to prevent illegal shipments of this waste and to close loopholes in the law.\n",
            "\n",
            "RO: Grupul PASOK a votat în favoarea propunerii alternative de rezoluţie a raportului Schmitt privind şcolile mai bune în UE, care a reuşit să elimine doar referirea la educaţia copiilor imigranţilor \"legali” şi care conţinea şi alte îmbunătăţiri.\n",
            "EN: The PASOK group voted in favour of the alternative motion for a resolution to the Schmitt report on better schools in the EU, which succeeded in deleting the reference to the education of children of 'legal' immigrants only and contained other improvements.\n",
            "\n",
            "RO: De aceea, noi, Uniunea Europeană, avem nevoie de un partener ca aceasta, un partener democratic, deoarece avem și diverse relații cu parteneri nedemocratici.\n",
            "EN: That is why we, the European Union, need a partner like this, a democratic partner, since we also have various relations with undemocratic partners.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLFsK1na5Vgt"
      },
      "source": [
        "We will use a subset of the Europarl en-ro corpus in our experiments. We separate the data intro train, dev and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9qL0Hqz5F6E"
      },
      "source": [
        "!sed -n 1,20000p data/shuf-Europarl.en-ro.both | cut -f 1 > data/train.ro\n",
        "!sed -n 1,20000p data/shuf-Europarl.en-ro.both | cut -f 2 > data/train.en"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Ux10Ye6Cr7"
      },
      "source": [
        "!sed -n 20001,21000p data/shuf-Europarl.en-ro.both | cut -f 1 > data/dev.ro\n",
        "!sed -n 20001,21000p data/shuf-Europarl.en-ro.both | cut -f 2 > data/dev.en"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrsFnsdB6Cv4"
      },
      "source": [
        "!sed -n 21001,21500p data/shuf-Europarl.en-ro.both | cut -f 1 > data/test.ro\n",
        "!sed -n 21001,21500p data/shuf-Europarl.en-ro.both | cut -f 2 > data/test.en"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1hOR9FK6XnA"
      },
      "source": [
        "###Text preprocessing\n",
        "\n",
        "We clean the texts and remove bad sentence pairs.\n",
        "\n",
        "* Removing the pairs in which at least one element of the pair (source or target) is empty. \n",
        "* Removing the pairs in which at least one of the sentences has 100 or more words. For simplicity, let's just split the sentences by whitespaces and consider the resulting pieces words; for example, the sentence `How are you?` will consist of 3 \"words\": `[\"How\", \"are\", \"you?\"]`.\n",
        "* Remove the pair if one sentence has at least 9 times as many words as the other one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI6St6qW6nuR"
      },
      "source": [
        "def clean_sentence_pairs(raw_lines):\n",
        "    # Remove pairs with empty sentences\n",
        "    clean_lines = [pair for pair in raw_lines\n",
        "                  if len(pair[0]) > 0 \n",
        "                  and len(pair[1]) > 0]\n",
        "    print(f'Pairs with empty lines removed: {len(raw_lines) - len(clean_lines)}')\n",
        "    raw_lines = clean_lines\n",
        "\n",
        "    # Remove very long sentences\n",
        "    clean_lines = [pair for pair in raw_lines\n",
        "                  if len(pair[0].split()) < 100 \n",
        "                  and len(pair[1].split()) < 100]\n",
        "    print(f'Pairs with long sentences removed: {len(raw_lines) - len(clean_lines)}')\n",
        "    raw_lines = clean_lines\n",
        "\n",
        "    # Remove pairs with high length ratios\n",
        "    clean_lines = [pair for pair in raw_lines\n",
        "                  if len(pair[0].split())/len(pair[1].split()) < 9\n",
        "                  and len(pair[1].split())/len(pair[0].split()) < 9]\n",
        "    print(f'Pairs with high length ratio removed: {len(raw_lines) - len(clean_lines)}')\n",
        "\n",
        "    return clean_lines"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfZhUpF7zyg"
      },
      "source": [
        "# Read source and target lines\n",
        "with open('data/train.en', 'r', encoding='utf8') as en_file:\n",
        "    en_lines = [line.strip() for line in en_file]\n",
        "with open('data/train.ro', 'r', encoding='utf8') as et_file:\n",
        "    et_lines = [line.strip() for line in et_file]\n",
        "\n",
        "input_pairs = [(en_lines[i], et_lines[i]) for i in range(len(en_lines))]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYeGcFVn8jBo",
        "outputId": "c10469cf-5c7a-4f28-d272-5e9363d07cd5"
      },
      "source": [
        "# Apply function to sentence pairs\n",
        "cleaned_pairs = clean_sentence_pairs(input_pairs)\n",
        "\n",
        "# Write the result into new files\n",
        "with open('data/cleaned-train.en', 'w', encoding='utf8') as en_clean_file:\n",
        "    en_clean_file.write('\\n'.join([pair[0] for pair in cleaned_pairs]))\n",
        "with open('cdata/leaned-train.ro', 'w', encoding='utf8') as et_clean_file:\n",
        "    et_clean_file.write('\\n'.join([pair[1] for pair in cleaned_pairs]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairs with empty lines removed: 0\n",
            "Pairs with long sentences removed: 31\n",
            "Pairs with high length ratio removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K15ySIn6-NJX"
      },
      "source": [
        "### 4. (Optional) Tokenization\n",
        "\n",
        "In a typical natural language processing pipeline, one of the main pre-processing steps is tokenization. Its task is to turn a string into a list of tokens, in other words, to separate words from punctuation marks (e.g. `Hi, Mary!` $\\rightarrow$ `[\"Hi\", \",\", \"Mary\", \"!\"]`). A typical choice of tokenizer for MT is `mosestokenizer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obcHnTNuMIcg"
      },
      "source": [
        "!pip install mosestokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26GhFjzh-73R",
        "outputId": "2caa4cf6-462f-44fc-a864-88524cf6cf42"
      },
      "source": [
        "from mosestokenizer import MosesTokenizer, MosesDetokenizer\n",
        "sentence = \"Am avut posibilitatea de a ne exprima aşteptările.\"\n",
        "\n",
        "with MosesTokenizer('en') as tokenizer:\n",
        "    tok_sentence = tokenizer(sentence)\n",
        "    print(f'Tokenized: {tok_sentence}')\n",
        "with MosesDetokenizer('en') as detokenizer:\n",
        "    detok_sentence = detokenizer(tok_sentence)\n",
        "    print(f'Detokenized: {detok_sentence}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized: ['Am', 'avut', 'posibilitatea', 'de', 'a', 'ne', 'exprima', 'aşteptările', '.']\n",
            "Detokenized: Am avut posibilitatea de a ne exprima aşteptările.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaSou4Yh_RjZ"
      },
      "source": [
        "However, tokenization has some drawbacks. It requires knowledge of patterns of the particular language at hand, and it is not always reversible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q78mkeX7_T-R",
        "outputId": "fc6e4754-04f2-4a1e-966a-28afa98471a5"
      },
      "source": [
        "test_sentence = \"Cele mai vechi atestări documentare ale termenului de „rumân/român” cunoscute în mod cert sunt conţinute în relatări, jurnale şi rapoarte de călătorie redactate de umanişti renascentişti din secolul al XVI-lea.\"\n",
        "\n",
        "with MosesTokenizer('en') as tokenizer:\n",
        "    tok_sentence = tokenizer(test_sentence)\n",
        "    print(f'Tokenized: {tok_sentence}')\n",
        "with MosesDetokenizer('en') as detokenizer:\n",
        "    detok_sentence = detokenizer(tok_sentence)\n",
        "    print(f'Detokenized: {detok_sentence}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized: ['Cele', 'mai', 'vechi', 'atestări', 'documentare', 'ale', 'termenului', 'de', '„', 'rumân', '/', 'român', '”', 'cunoscute', 'în', 'mod', 'cert', 'sunt', 'conţinute', 'în', 'relatări', ',', 'jurnale', 'şi', 'rapoarte', 'de', 'călătorie', 'redactate', 'de', 'umanişti', 'renascentişti', 'din', 'secolul', 'al', 'XVI', '@-@', 'lea', '.']\n",
            "Detokenized: Cele mai vechi atestări documentare ale termenului de „rumân / român ” cunoscute în mod cert sunt conţinute în relatări, jurnale şi rapoarte de călătorie redactate de umanişti renascentişti din secolul al XVI-lea.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZnKdYd3_2Qu"
      },
      "source": [
        "As you can see, when we tokenize this sentence and then detokenize it again, it is not reproduced correctly. While this would not be a problem, for example, for text classification, it is a problem for MT. Firstly, we want to have natural-looking output, and secondly, unexpected whitespaces mean that our translations will get a low BLEU score.\n",
        "\n",
        "In this tutorial, we **will not** tokenize our data, because SentencePiece, which we will use for subword segmentation (see section 6 of this notebook) can handle untokenized text. It is also language-independent and reversible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azq-oC3M_3Kr"
      },
      "source": [
        "### 5. (Optional) Truecasing\n",
        "\n",
        "As the next step, we need to deal with capitalization. We have three options:\n",
        "\n",
        "1. Lowercase everything\n",
        "2. Use a truecaser\n",
        "3. Do nothing\n",
        "\n",
        "**Truecasing** is the process of restoring\n",
        "case information to badly-cased or noncased text.\n",
        "\n",
        "We will use the MosesTruecaser from [sacremoses](https://github.com/alvations/sacremoses)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypY1KnCQBZ6H",
        "outputId": "617d6182-e633-4f43-acb1-5af9b496ef2f"
      },
      "source": [
        "pip install -U sacremoses"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.62.3)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rutKjLMRBq-L"
      },
      "source": [
        "We will have to train the truecaser on our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpQtob4KBqXZ"
      },
      "source": [
        "from sacremoses import MosesTruecaser, MosesTokenizer\n",
        "\n",
        "mtr = MosesTruecaser()\n",
        "rotok = MosesTokenizer(lang='ro')\n",
        "\n",
        "tokenized_docs = [rotok.tokenize(line) for line in open('data/cleaned-train.ro')]\n",
        "mtr.train(tokenized_docs, save_to='model/ro.truecasemodel')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7DgtMREYr3"
      },
      "source": [
        "mtr = MosesTruecaser()\n",
        "entok = MosesTokenizer(lang='en')\n",
        "\n",
        "tokenized_docs = [entok.tokenize(line) for line in open('data/cleaned-train.en')]\n",
        "mtr.train(tokenized_docs, save_to='model/en.truecasemodel')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xmhHFXkE6ua"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szj6JlCMDZ2k"
      },
      "source": [
        "Using the trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-l_Z9_DYnf"
      },
      "source": [
        "!sacremoses -j 14 truecase -m model/ro.truecasemodel < data/cleaned-train.ro > data/tc_cleaned-train.ro\n",
        "!sacremoses -j 14 truecase -m model/en.truecasemodel < data/cleaned-train.en > data/tc_cleaned-train.en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmL7kIPxE4En"
      },
      "source": [
        "### 6. Subword segmentation\n",
        "\n",
        "The last preprocessing step is subword segmentation. Words will be split into smaller parts based on character co-occurrence frequency. The most common words will remain in one piece, and rare words will be broken into several units.\n",
        "\n",
        "We will use [SentencePiece](https://github.com/google/sentencepiece)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_RvzYUIMLsE",
        "outputId": "25b49d1e-c1af-46fe-fc0b-666883f6f053"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FOppWIqMZf7"
      },
      "source": [
        "We can train a model for splitting our text into subwords. Note that it is common to have a joint vocabulary for source and target languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFyJ7rHVMd-H"
      },
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.train(input=['data/cleaned-train.en', 'data/cleaned-train.ro'],\n",
        "                               model_prefix='model/sentpiece',\n",
        "                               vocab_size=4000)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM23FRA6MpDy",
        "outputId": "e7168778-00e5-4812-c158-df400591959c"
      },
      "source": [
        "sp = spm.SentencePieceProcessor(model_file='model/sentpiece.model')\n",
        "encoded = sp.encode('Am avut posibilitatea de a ne exprima aşteptările.', out_type=str)\n",
        "print(encoded)\n",
        "encoded_str = ' '.join(encoded)\n",
        "print(encoded_str)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁Am', '▁avut', '▁posibilitatea', '▁de', '▁a', '▁ne', '▁exprim', 'a', '▁aştept', 'ările', '.']\n",
            "▁Am ▁avut ▁posibilitatea ▁de ▁a ▁ne ▁exprim a ▁aştept ările .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdvNApsKMz-k"
      },
      "source": [
        "We have trained a model with 4000 subwords. This means that SentencePiece will split the words so that the vocabulary size will be 4000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdV5xs3aM_8W"
      },
      "source": [
        "We will apply the model on the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvOA_XlLM8iz"
      },
      "source": [
        "for filename in ['data/cleaned-train.en', 'data/cleaned-train.ro']:\n",
        "    with open(f'{filename}', 'r', encoding='utf8') as in_fh:\n",
        "        sp_out = sp.encode([line.strip() for line in in_fh], out_type=str)\n",
        "    with open(f'data/sentpiece-{filename}', 'w', encoding='utf8') as out_fh:\n",
        "        out_fh.writelines([' '.join(line) + '\\n' for line in sp_out])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCLOxiwbNOZN",
        "outputId": "c1c94f4e-06c1-465f-e0e8-8839ae3bf207"
      },
      "source": [
        "with open(f'data/sentpiece-cleaned-train.ro', 'r') as f:\n",
        "    sentpieces_ro = f.readlines()\n",
        "print(sentpieces_ro[:2])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁Aş ▁dori ▁să ▁î i ▁mulţumesc ▁în ▁mod ▁deosebit ▁raport oare i , ▁dn a ▁L y n ne , ▁pentru ▁munca ▁excelent ă ▁în ▁în to c mi rea ▁propuneri i ▁de ▁rezoluţie ▁referito are ▁la ▁propunerea ▁Comisiei ▁şi ▁pentru ▁eforturile ▁sale , ▁de - a ▁lung ul ▁mai ▁mult or ▁ani , ▁în ▁vedere a ▁îmbunătăţ i rii ▁sănătăţii ▁şi ▁siguranţ ei ▁la ▁loc ul ▁de ▁muncă ▁pentru ▁lucră torii ▁din ▁sectorul ▁sp it al ic esc ▁şi ▁al ▁asistenţ ei ▁medical e .\\n', '▁Aceste a ▁ridic ă ▁între ▁noi ▁bariere ▁in ut ile ▁pe ▁care , ▁la ▁urma ▁ ur m elor , ▁le - am ▁de m on t at ▁timp ▁de ▁de ce ni i ▁şi ▁aşa ▁trebuie ▁să ▁facem ▁şi ▁pe ▁viitor .\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfW33jU-NrvG"
      },
      "source": [
        "###Repeat for dev sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZjujyC5N2-_",
        "outputId": "05777527-794b-4bcb-fd85-e60a709841e2"
      },
      "source": [
        "# Cleaning\n",
        "\n",
        "# Read source and target lines\n",
        "with open('data/dev.en', 'r', encoding='utf8') as en_file:\n",
        "    en_lines = [line.strip() for line in en_file]\n",
        "with open('data/dev.ro', 'r', encoding='utf8') as et_file:\n",
        "    et_lines = [line.strip() for line in et_file]\n",
        "\n",
        "input_pairs = [(en_lines[i], et_lines[i]) for i in range(len(en_lines))]\n",
        "\n",
        "# Apply function to sentence pairs\n",
        "cleaned_pairs = clean_sentence_pairs(input_pairs)\n",
        "\n",
        "# Write the result into new files\n",
        "with open('data/cleaned-dev.en', 'w', encoding='utf8') as en_clean_file:\n",
        "    en_clean_file.write('\\n'.join([pair[0] for pair in cleaned_pairs]))\n",
        "with open('data/cleaned-dev.ro', 'w', encoding='utf8') as et_clean_file:\n",
        "    et_clean_file.write('\\n'.join([pair[1] for pair in cleaned_pairs]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairs with empty lines removed: 0\n",
            "Pairs with long sentences removed: 1\n",
            "Pairs with high length ratio removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9bJEY-LOBSn"
      },
      "source": [
        "# Subword segmentation\n",
        "for filename in ['data/cleaned-dev.en', 'data/cleaned-dev.ro']:\n",
        "    with open(f'{filename}', 'r', encoding='utf8') as in_fh:\n",
        "        sp_out = sp.encode([line.strip() for line in in_fh], out_type=str)\n",
        "    with open(f'data/sentpiece-{filename}', 'w', encoding='utf8') as out_fh:\n",
        "        out_fh.writelines([' '.join(line) + '\\n' for line in sp_out])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCDpBDKqO9wv"
      },
      "source": [
        "We need to write the training and dev data into binary filesfrom which `fairseq` will read during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNt2IAT7PQr6",
        "outputId": "075a5d5c-ebf2-4a40-d9f3-6c9098050c4f"
      },
      "source": [
        "!fairseq-preprocess --source-lang ro \\\n",
        "                    --target-lang en \\\n",
        "                    --trainpref data/sentpiece-cleaned-train \\\n",
        "                    --validpref data/sentpiece-cleaned-dev \\\n",
        "                    --destdir data/bin-data \\\n",
        "                    --joined-dictionary"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-20 19:51:34 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data/bin-data', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ro', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='data/sentpiece-cleaned-train', user_dir=None, validpref='data/sentpiece-cleaned-dev', workers=1)\n",
            "2021-10-20 19:51:39 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 4088 types\n",
            "2021-10-20 19:51:43 | INFO | fairseq_cli.preprocess | [ro] data/sentpiece-cleaned-train.ro: 19969 sents, 833669 tokens, 0.0% replaced by <unk>\n",
            "2021-10-20 19:51:43 | INFO | fairseq_cli.preprocess | [ro] Dictionary: 4088 types\n",
            "2021-10-20 19:51:44 | INFO | fairseq_cli.preprocess | [ro] data/sentpiece-cleaned-dev.ro: 999 sents, 41046 tokens, 0.00487% replaced by <unk>\n",
            "2021-10-20 19:51:44 | INFO | fairseq_cli.preprocess | [en] Dictionary: 4088 types\n",
            "2021-10-20 19:51:48 | INFO | fairseq_cli.preprocess | [en] data/sentpiece-cleaned-train.en: 19969 sents, 739165 tokens, 0.0% replaced by <unk>\n",
            "2021-10-20 19:51:48 | INFO | fairseq_cli.preprocess | [en] Dictionary: 4088 types\n",
            "2021-10-20 19:51:48 | INFO | fairseq_cli.preprocess | [en] data/sentpiece-cleaned-dev.en: 999 sents, 36372 tokens, 0.00275% replaced by <unk>\n",
            "2021-10-20 19:51:48 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data/bin-data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfc4LFydPbZP"
      },
      "source": [
        "###Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfIGM0OePiu_"
      },
      "source": [
        "Now that we have preprocessed some texts, we are finally ready to train a translation model. It will not be very good, because we are only using 20,000 sentence pairs for training and we do not have a lot of time, but nevertheless it should learn something useful.\n",
        "\n",
        "Run the command below. It will train a model with 2-layer Transformer encoder and decoder for 10 epochs. This will take some time. (Check that you have selected runtime type 'GPU'.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUogTmwHRKca",
        "outputId": "58ba5eb7-6626-4062-9666-104301d196bf"
      },
      "source": [
        "!pip uninstall sacrebleu\n",
        "!pip install sacrebleu==1.5.1"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: sacrebleu 2.0.0\n",
            "Uninstalling sacrebleu-2.0.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/sacrebleu\n",
            "    /usr/local/lib/python3.7/dist-packages/sacrebleu-2.0.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/sacrebleu/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled sacrebleu-2.0.0\n",
            "Collecting sacrebleu==1.5.1\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 2.3.2\n",
            "    Uninstalling portalocker-2.3.2:\n",
            "      Successfully uninstalled portalocker-2.3.2\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QaddsZ_PsFa",
        "outputId": "ec24a36a-9ec1-4b8e-c7ad-48609561b3cd"
      },
      "source": [
        "!fairseq-train data/bin-data --arch transformer \\\n",
        "                             --lr 0.005 \\\n",
        "                             --encoder-attention-heads 4 \\\n",
        "                             --encoder-embed-dim 32 \\\n",
        "                             --encoder-layers 2 \\\n",
        "                             --encoder-ffn-embed-dim 64 \\\n",
        "                             --decoder-attention-heads 4 \\\n",
        "                             --decoder-embed-dim 32 \\\n",
        "                             --decoder-layers 2 \\\n",
        "                             --decoder-ffn-embed-dim 64 \\\n",
        "                             --max-epoch 10 \\\n",
        "                             --optimizer adam \\\n",
        "                             --max-tokens 4000 \\\n",
        "                             --save-dir data/et2en_model \\\n",
        "                             --log-format json \\\n",
        "                             --tensorboard-logdir data/et2en_model/log-tb \\\n",
        "                             --eval-bleu \\\n",
        "                             --eval-bleu-remove-bpe=sentencepiece"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='cross_entropy', cross_self_attention=False, curriculum=0, data='data/bin-data', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=32, decoder_embed_path=None, decoder_ffn_embed_dim=64, decoder_input_dim=32, decoder_layerdrop=0, decoder_layers=2, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=32, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=32, encoder_embed_path=None, encoder_ffn_embed_dim=64, encoder_layerdrop=0, encoder_layers=2, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[0.005], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=10, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='data/et2en_model', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation', tensorboard_logdir='data/et2en_model/log-tb', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, weight_decay=0.0, zero_sharding='none')\n",
            "2021-10-20 19:54:47 | INFO | fairseq.tasks.translation | [ro] dictionary: 4088 types\n",
            "2021-10-20 19:54:47 | INFO | fairseq.tasks.translation | [en] dictionary: 4088 types\n",
            "2021-10-20 19:54:47 | INFO | fairseq.data.data_utils | loaded 999 examples from: data/bin-data/valid.ro-en.ro\n",
            "2021-10-20 19:54:47 | INFO | fairseq.data.data_utils | loaded 999 examples from: data/bin-data/valid.ro-en.en\n",
            "2021-10-20 19:54:47 | INFO | fairseq.tasks.translation | data/bin-data valid ro-en 999 examples\n",
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(4088, 32, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
            "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
            "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(4088, 32, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
            "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
            "        (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (output_projection): Linear(in_features=32, out_features=4088, bias=False)\n",
            "  )\n",
            ")\n",
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | model: transformer (TransformerModel)\n",
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | criterion: cross_entropy (CrossEntropyCriterion)\n",
            "2021-10-20 19:54:47 | INFO | fairseq_cli.train | num. model params: 435200 (num. trained: 435200)\n",
            "2021-10-20 19:54:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-10-20 19:54:49 | INFO | fairseq.utils | rank   0: capabilities =  3.7  ; total memory = 11.173 GB ; name = Tesla K80                               \n",
            "2021-10-20 19:54:49 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-10-20 19:54:49 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-10-20 19:54:49 | INFO | fairseq_cli.train | max tokens per GPU = 4000 and max sentences per GPU = None\n",
            "2021-10-20 19:54:49 | INFO | fairseq.trainer | no existing checkpoint found data/et2en_model/checkpoint_last.pt\n",
            "2021-10-20 19:54:49 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-10-20 19:54:49 | INFO | fairseq.data.data_utils | loaded 19969 examples from: data/bin-data/train.ro-en.ro\n",
            "2021-10-20 19:54:49 | INFO | fairseq.data.data_utils | loaded 19969 examples from: data/bin-data/train.ro-en.en\n",
            "2021-10-20 19:54:49 | INFO | fairseq.tasks.translation | data/bin-data train ro-en 19969 examples\n",
            "2021-10-20 19:54:49 | INFO | fairseq.trainer | begin training epoch 1\n",
            "/usr/local/lib/python3.7/dist-packages/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "2021-10-20 19:54:56 | INFO | train_inner | {\"epoch\": 1, \"update\": 0.397, \"loss\": \"8.83\", \"ppl\": \"454.94\", \"wps\": \"48800.7\", \"ups\": \"16.6\", \"wpb\": \"2945.4\", \"bsz\": \"80.7\", \"num_updates\": \"100\", \"lr\": \"0.005\", \"gnorm\": \"0.42\", \"train_wall\": \"6\", \"wall\": \"6\"}\n",
            "2021-10-20 19:55:02 | INFO | train_inner | {\"epoch\": 1, \"update\": 0.794, \"loss\": \"7.247\", \"ppl\": \"151.88\", \"wps\": \"48863.5\", \"ups\": \"16.66\", \"wpb\": \"2933.3\", \"bsz\": \"76.1\", \"num_updates\": \"200\", \"lr\": \"0.005\", \"gnorm\": \"0.425\", \"train_wall\": \"6\", \"wall\": \"12\"}\n",
            "2021-10-20 19:55:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n",
            "2021-10-20 19:55:16 | INFO | valid | {\"epoch\": 1, \"valid_loss\": \"6.569\", \"valid_ppl\": \"94.93\", \"valid_bleu\": \"1.36\", \"valid_wps\": \"3261.2\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"252\"}\n",
            "2021-10-20 19:55:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:55:16 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint1.pt (epoch 1 @ 252 updates, score 6.569) (writing took 0.045495844000015495 seconds)\n",
            "2021-10-20 19:55:16 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-10-20 19:55:16 | INFO | train | {\"epoch\": 1, \"train_loss\": \"7.791\", \"train_ppl\": \"221.53\", \"train_wps\": \"27956.8\", \"train_ups\": \"9.54\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"252\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.409\", \"train_train_wall\": \"15\", \"train_wall\": \"27\"}\n",
            "2021-10-20 19:55:16 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-10-20 19:55:19 | INFO | train_inner | {\"epoch\": 2, \"update\": 1.19, \"loss\": \"6.7\", \"ppl\": \"103.94\", \"wps\": \"16567.3\", \"ups\": \"5.65\", \"wpb\": \"2932.3\", \"bsz\": \"84.2\", \"num_updates\": \"300\", \"lr\": \"0.005\", \"gnorm\": \"0.363\", \"train_wall\": \"6\", \"wall\": \"30\"}\n",
            "2021-10-20 19:55:25 | INFO | train_inner | {\"epoch\": 2, \"update\": 1.587, \"loss\": \"6.454\", \"ppl\": \"87.68\", \"wps\": \"48568.2\", \"ups\": \"16.61\", \"wpb\": \"2924.2\", \"bsz\": \"76.9\", \"num_updates\": \"400\", \"lr\": \"0.005\", \"gnorm\": \"0.36\", \"train_wall\": \"6\", \"wall\": \"36\"}\n",
            "2021-10-20 19:55:31 | INFO | train_inner | {\"epoch\": 2, \"update\": 1.984, \"loss\": \"6.319\", \"ppl\": \"79.86\", \"wps\": \"49632.6\", \"ups\": \"16.91\", \"wpb\": \"2935.3\", \"bsz\": \"79.5\", \"num_updates\": \"500\", \"lr\": \"0.005\", \"gnorm\": \"0.451\", \"train_wall\": \"6\", \"wall\": \"42\"}\n",
            "2021-10-20 19:55:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:55:53 | INFO | valid | {\"epoch\": 2, \"valid_loss\": \"6.207\", \"valid_ppl\": \"73.88\", \"valid_bleu\": \"3.09\", \"valid_wps\": \"1718\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"504\", \"valid_best_loss\": \"6.207\"}\n",
            "2021-10-20 19:55:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:55:53 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint2.pt (epoch 2 @ 504 updates, score 6.207) (writing took 0.05067879699981859 seconds)\n",
            "2021-10-20 19:55:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-10-20 19:55:53 | INFO | train | {\"epoch\": 2, \"train_loss\": \"6.424\", \"train_ppl\": \"85.86\", \"train_wps\": \"20085.4\", \"train_ups\": \"6.85\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"504\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.4\", \"train_train_wall\": \"15\", \"train_wall\": \"63\"}\n",
            "2021-10-20 19:55:53 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-10-20 19:55:58 | INFO | train_inner | {\"epoch\": 3, \"update\": 2.381, \"loss\": \"6.178\", \"ppl\": \"72.43\", \"wps\": \"10896.1\", \"ups\": \"3.67\", \"wpb\": \"2971\", \"bsz\": \"79\", \"num_updates\": \"600\", \"lr\": \"0.005\", \"gnorm\": \"0.435\", \"train_wall\": \"6\", \"wall\": \"69\"}\n",
            "2021-10-20 19:56:04 | INFO | train_inner | {\"epoch\": 3, \"update\": 2.778, \"loss\": \"6.033\", \"ppl\": \"65.47\", \"wps\": \"49430.9\", \"ups\": \"17.08\", \"wpb\": \"2894.3\", \"bsz\": \"81.2\", \"num_updates\": \"700\", \"lr\": \"0.005\", \"gnorm\": \"0.416\", \"train_wall\": \"6\", \"wall\": \"75\"}\n",
            "2021-10-20 19:56:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:56:25 | INFO | valid | {\"epoch\": 3, \"valid_loss\": \"5.838\", \"valid_ppl\": \"57.22\", \"valid_bleu\": \"5.41\", \"valid_wps\": \"2023.8\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"756\", \"valid_best_loss\": \"5.838\"}\n",
            "2021-10-20 19:56:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:56:26 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint3.pt (epoch 3 @ 756 updates, score 5.838) (writing took 0.04601654599991889 seconds)\n",
            "2021-10-20 19:56:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-10-20 19:56:26 | INFO | train | {\"epoch\": 3, \"train_loss\": \"6.086\", \"train_ppl\": \"67.94\", \"train_wps\": \"22523.5\", \"train_ups\": \"7.68\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"756\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.44\", \"train_train_wall\": \"14\", \"train_wall\": \"96\"}\n",
            "2021-10-20 19:56:26 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2021-10-20 19:56:28 | INFO | train_inner | {\"epoch\": 4, \"update\": 3.175, \"loss\": \"6.01\", \"ppl\": \"64.45\", \"wps\": \"12058.6\", \"ups\": \"4.16\", \"wpb\": \"2898.3\", \"bsz\": \"72.1\", \"num_updates\": \"800\", \"lr\": \"0.005\", \"gnorm\": \"0.48\", \"train_wall\": \"6\", \"wall\": \"99\"}\n",
            "2021-10-20 19:56:34 | INFO | train_inner | {\"epoch\": 4, \"update\": 3.571, \"loss\": \"5.799\", \"ppl\": \"55.68\", \"wps\": \"48964.4\", \"ups\": \"16.68\", \"wpb\": \"2934.8\", \"bsz\": \"85.8\", \"num_updates\": \"900\", \"lr\": \"0.005\", \"gnorm\": \"0.466\", \"train_wall\": \"6\", \"wall\": \"105\"}\n",
            "2021-10-20 19:56:40 | INFO | train_inner | {\"epoch\": 4, \"update\": 3.968, \"loss\": \"5.833\", \"ppl\": \"56.99\", \"wps\": \"49173.6\", \"ups\": \"16.7\", \"wpb\": \"2943.7\", \"bsz\": \"78.6\", \"num_updates\": \"1000\", \"lr\": \"0.005\", \"gnorm\": \"0.472\", \"train_wall\": \"6\", \"wall\": \"111\"}\n",
            "2021-10-20 19:56:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:56:57 | INFO | valid | {\"epoch\": 4, \"valid_loss\": \"5.61\", \"valid_ppl\": \"48.84\", \"valid_bleu\": \"6.95\", \"valid_wps\": \"2215.6\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"1008\", \"valid_best_loss\": \"5.61\"}\n",
            "2021-10-20 19:56:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:56:57 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint4.pt (epoch 4 @ 1008 updates, score 5.61) (writing took 0.04558314599989899 seconds)\n",
            "2021-10-20 19:56:57 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2021-10-20 19:56:57 | INFO | train | {\"epoch\": 4, \"train_loss\": \"5.847\", \"train_ppl\": \"57.55\", \"train_wps\": \"23346.6\", \"train_ups\": \"7.96\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"1008\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.466\", \"train_train_wall\": \"15\", \"train_wall\": \"128\"}\n",
            "2021-10-20 19:56:57 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2021-10-20 19:57:03 | INFO | train_inner | {\"epoch\": 5, \"update\": 4.365, \"loss\": \"5.679\", \"ppl\": \"51.25\", \"wps\": \"13228.3\", \"ups\": \"4.47\", \"wpb\": \"2958.6\", \"bsz\": \"81.8\", \"num_updates\": \"1100\", \"lr\": \"0.005\", \"gnorm\": \"0.557\", \"train_wall\": \"6\", \"wall\": \"133\"}\n",
            "2021-10-20 19:57:08 | INFO | train_inner | {\"epoch\": 5, \"update\": 4.762, \"loss\": \"5.747\", \"ppl\": \"53.71\", \"wps\": \"51031.1\", \"ups\": \"17.48\", \"wpb\": \"2919.5\", \"bsz\": \"74.6\", \"num_updates\": \"1200\", \"lr\": \"0.005\", \"gnorm\": \"0.527\", \"train_wall\": \"6\", \"wall\": \"139\"}\n",
            "2021-10-20 19:57:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:57:25 | INFO | valid | {\"epoch\": 5, \"valid_loss\": \"5.472\", \"valid_ppl\": \"44.37\", \"valid_bleu\": \"7.51\", \"valid_wps\": \"2670.2\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"1260\", \"valid_best_loss\": \"5.472\"}\n",
            "2021-10-20 19:57:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:57:26 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint5.pt (epoch 5 @ 1260 updates, score 5.472) (writing took 0.04549297399989882 seconds)\n",
            "2021-10-20 19:57:26 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2021-10-20 19:57:26 | INFO | train | {\"epoch\": 5, \"train_loss\": \"5.696\", \"train_ppl\": \"51.84\", \"train_wps\": \"26085.6\", \"train_ups\": \"8.89\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"1260\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.535\", \"train_train_wall\": \"14\", \"train_wall\": \"156\"}\n",
            "2021-10-20 19:57:26 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2021-10-20 19:57:28 | INFO | train_inner | {\"epoch\": 6, \"update\": 5.159, \"loss\": \"5.587\", \"ppl\": \"48.06\", \"wps\": \"15151.7\", \"ups\": \"5.06\", \"wpb\": \"2992.8\", \"bsz\": \"82.1\", \"num_updates\": \"1300\", \"lr\": \"0.005\", \"gnorm\": \"0.526\", \"train_wall\": \"6\", \"wall\": \"159\"}\n",
            "2021-10-20 19:57:34 | INFO | train_inner | {\"epoch\": 6, \"update\": 5.556, \"loss\": \"5.547\", \"ppl\": \"46.75\", \"wps\": \"47690.3\", \"ups\": \"16.2\", \"wpb\": \"2944.5\", \"bsz\": \"78.2\", \"num_updates\": \"1400\", \"lr\": \"0.005\", \"gnorm\": \"0.516\", \"train_wall\": \"6\", \"wall\": \"165\"}\n",
            "2021-10-20 19:57:40 | INFO | train_inner | {\"epoch\": 6, \"update\": 5.952, \"loss\": \"5.588\", \"ppl\": \"48.12\", \"wps\": \"47859.2\", \"ups\": \"16.63\", \"wpb\": \"2877.9\", \"bsz\": \"79\", \"num_updates\": \"1500\", \"lr\": \"0.005\", \"gnorm\": \"0.63\", \"train_wall\": \"6\", \"wall\": \"171\"}\n",
            "2021-10-20 19:57:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:57:54 | INFO | valid | {\"epoch\": 6, \"valid_loss\": \"5.391\", \"valid_ppl\": \"41.97\", \"valid_bleu\": \"7.94\", \"valid_wps\": \"2880.8\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"1512\", \"valid_best_loss\": \"5.391\"}\n",
            "2021-10-20 19:57:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:57:54 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint6.pt (epoch 6 @ 1512 updates, score 5.391) (writing took 0.0448802800001431 seconds)\n",
            "2021-10-20 19:57:54 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2021-10-20 19:57:54 | INFO | train | {\"epoch\": 6, \"train_loss\": \"5.553\", \"train_ppl\": \"46.96\", \"train_wps\": \"26076.5\", \"train_ups\": \"8.89\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"1512\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.574\", \"train_train_wall\": \"15\", \"train_wall\": \"185\"}\n",
            "2021-10-20 19:57:54 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2021-10-20 19:57:59 | INFO | train_inner | {\"epoch\": 7, \"update\": 6.349, \"loss\": \"5.489\", \"ppl\": \"44.9\", \"wps\": \"15168.1\", \"ups\": \"5.3\", \"wpb\": \"2864.1\", \"bsz\": \"76.5\", \"num_updates\": \"1600\", \"lr\": \"0.005\", \"gnorm\": \"0.6\", \"train_wall\": \"6\", \"wall\": \"190\"}\n",
            "2021-10-20 19:58:05 | INFO | train_inner | {\"epoch\": 7, \"update\": 6.746, \"loss\": \"5.479\", \"ppl\": \"44.61\", \"wps\": \"50422.7\", \"ups\": \"16.96\", \"wpb\": \"2972.9\", \"bsz\": \"77\", \"num_updates\": \"1700\", \"lr\": \"0.005\", \"gnorm\": \"0.587\", \"train_wall\": \"6\", \"wall\": \"196\"}\n",
            "2021-10-20 19:58:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:58:27 | INFO | valid | {\"epoch\": 7, \"valid_loss\": \"5.264\", \"valid_ppl\": \"38.42\", \"valid_bleu\": \"7.94\", \"valid_wps\": \"2010.6\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"1764\", \"valid_best_loss\": \"5.264\"}\n",
            "2021-10-20 19:58:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:58:27 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint7.pt (epoch 7 @ 1764 updates, score 5.264) (writing took 0.04651723999995738 seconds)\n",
            "2021-10-20 19:58:27 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2021-10-20 19:58:27 | INFO | train | {\"epoch\": 7, \"train_loss\": \"5.441\", \"train_ppl\": \"43.45\", \"train_wps\": \"22342.1\", \"train_ups\": \"7.62\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"1764\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.59\", \"train_train_wall\": \"15\", \"train_wall\": \"218\"}\n",
            "2021-10-20 19:58:27 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2021-10-20 19:58:29 | INFO | train_inner | {\"epoch\": 8, \"update\": 7.143, \"loss\": \"5.338\", \"ppl\": \"40.44\", \"wps\": \"12213.6\", \"ups\": \"4.13\", \"wpb\": \"2957.6\", \"bsz\": \"81.8\", \"num_updates\": \"1800\", \"lr\": \"0.005\", \"gnorm\": \"0.592\", \"train_wall\": \"6\", \"wall\": \"220\"}\n",
            "2021-10-20 19:58:35 | INFO | train_inner | {\"epoch\": 8, \"update\": 7.54, \"loss\": \"5.301\", \"ppl\": \"39.42\", \"wps\": \"47647.8\", \"ups\": \"16.75\", \"wpb\": \"2845.3\", \"bsz\": \"85\", \"num_updates\": \"1900\", \"lr\": \"0.005\", \"gnorm\": \"0.649\", \"train_wall\": \"6\", \"wall\": \"226\"}\n",
            "2021-10-20 19:58:41 | INFO | train_inner | {\"epoch\": 8, \"update\": 7.937, \"loss\": \"5.414\", \"ppl\": \"42.64\", \"wps\": \"49722.8\", \"ups\": \"16.49\", \"wpb\": \"3014.9\", \"bsz\": \"75.7\", \"num_updates\": \"2000\", \"lr\": \"0.005\", \"gnorm\": \"0.624\", \"train_wall\": \"6\", \"wall\": \"232\"}\n",
            "2021-10-20 19:58:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:58:58 | INFO | valid | {\"epoch\": 8, \"valid_loss\": \"5.142\", \"valid_ppl\": \"35.32\", \"valid_bleu\": \"10.02\", \"valid_wps\": \"2250.9\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"2016\", \"valid_best_loss\": \"5.142\"}\n",
            "2021-10-20 19:58:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:58:58 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint8.pt (epoch 8 @ 2016 updates, score 5.142) (writing took 0.04203080700017381 seconds)\n",
            "2021-10-20 19:58:58 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2021-10-20 19:58:58 | INFO | train | {\"epoch\": 8, \"train_loss\": \"5.355\", \"train_ppl\": \"40.92\", \"train_wps\": \"23463.8\", \"train_ups\": \"8\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"2016\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.631\", \"train_train_wall\": \"15\", \"train_wall\": \"249\"}\n",
            "2021-10-20 19:58:59 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2021-10-20 19:59:04 | INFO | train_inner | {\"epoch\": 9, \"update\": 8.333, \"loss\": \"5.256\", \"ppl\": \"38.22\", \"wps\": \"13021.4\", \"ups\": \"4.48\", \"wpb\": \"2905\", \"bsz\": \"78.9\", \"num_updates\": \"2100\", \"lr\": \"0.005\", \"gnorm\": \"0.619\", \"train_wall\": \"6\", \"wall\": \"254\"}\n",
            "2021-10-20 19:59:10 | INFO | train_inner | {\"epoch\": 9, \"update\": 8.73, \"loss\": \"5.28\", \"ppl\": \"38.85\", \"wps\": \"50255.4\", \"ups\": \"16.79\", \"wpb\": \"2993.2\", \"bsz\": \"79.1\", \"num_updates\": \"2200\", \"lr\": \"0.005\", \"gnorm\": \"0.669\", \"train_wall\": \"6\", \"wall\": \"260\"}\n",
            "2021-10-20 19:59:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 19:59:32 | INFO | valid | {\"epoch\": 9, \"valid_loss\": \"5.136\", \"valid_ppl\": \"35.17\", \"valid_bleu\": \"8.03\", \"valid_wps\": \"1967.8\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"2268\", \"valid_best_loss\": \"5.136\"}\n",
            "2021-10-20 19:59:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 19:59:32 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint9.pt (epoch 9 @ 2268 updates, score 5.136) (writing took 0.04386836899993796 seconds)\n",
            "2021-10-20 19:59:32 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2021-10-20 19:59:32 | INFO | train | {\"epoch\": 9, \"train_loss\": \"5.266\", \"train_ppl\": \"38.47\", \"train_wps\": \"21994.9\", \"train_ups\": \"7.5\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"2268\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.652\", \"train_train_wall\": \"15\", \"train_wall\": \"283\"}\n",
            "2021-10-20 19:59:32 | INFO | fairseq.trainer | begin training epoch 10\n",
            "2021-10-20 19:59:34 | INFO | train_inner | {\"epoch\": 10, \"update\": 9.127, \"loss\": \"5.269\", \"ppl\": \"38.56\", \"wps\": \"11774.4\", \"ups\": \"4.1\", \"wpb\": \"2872.6\", \"bsz\": \"77\", \"num_updates\": \"2300\", \"lr\": \"0.005\", \"gnorm\": \"0.664\", \"train_wall\": \"6\", \"wall\": \"285\"}\n",
            "2021-10-20 19:59:40 | INFO | train_inner | {\"epoch\": 10, \"update\": 9.524, \"loss\": \"5.171\", \"ppl\": \"36.03\", \"wps\": \"49505\", \"ups\": \"16.82\", \"wpb\": \"2943.9\", \"bsz\": \"83.5\", \"num_updates\": \"2400\", \"lr\": \"0.005\", \"gnorm\": \"0.723\", \"train_wall\": \"6\", \"wall\": \"291\"}\n",
            "2021-10-20 19:59:46 | INFO | train_inner | {\"epoch\": 10, \"update\": 9.921, \"loss\": \"5.286\", \"ppl\": \"39\", \"wps\": \"51463.2\", \"ups\": \"17.43\", \"wpb\": \"2952.6\", \"bsz\": \"76.4\", \"num_updates\": \"2500\", \"lr\": \"0.005\", \"gnorm\": \"0.697\", \"train_wall\": \"6\", \"wall\": \"297\"}\n",
            "2021-10-20 19:59:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-10-20 20:00:00 | INFO | valid | {\"epoch\": 10, \"valid_loss\": \"5.041\", \"valid_ppl\": \"32.93\", \"valid_bleu\": \"11.42\", \"valid_wps\": \"2775.8\", \"valid_wpb\": \"2598\", \"valid_bsz\": \"71.4\", \"valid_num_updates\": \"2520\", \"valid_best_loss\": \"5.041\"}\n",
            "2021-10-20 20:00:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
            "2021-10-20 20:00:00 | INFO | fairseq.checkpoint_utils | saved checkpoint data/et2en_model/checkpoint10.pt (epoch 10 @ 2520 updates, score 5.041) (writing took 0.041104579999682755 seconds)\n",
            "2021-10-20 20:00:00 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2021-10-20 20:00:00 | INFO | train | {\"epoch\": 10, \"train_loss\": \"5.219\", \"train_ppl\": \"37.25\", \"train_wps\": \"26408.1\", \"train_ups\": \"9\", \"train_wpb\": \"2933.2\", \"train_bsz\": \"79.2\", \"train_num_updates\": \"2520\", \"train_lr\": \"0.005\", \"train_gnorm\": \"0.703\", \"train_train_wall\": \"14\", \"train_wall\": \"311\"}\n",
            "2021-10-20 20:00:00 | INFO | fairseq_cli.train | done training in 310.8 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb_QB2w2RvzX"
      },
      "source": [
        "Given the small training set, we got low BLEU scores at validation, which indicates that our model did not learn to translate well yet, but is not generating completely random output either."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "544CvVreRu1q"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir data/et2en_model/log-tb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj9Qa2p7R9qo"
      },
      "source": [
        "###Translating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmlfKPJ9SGT8"
      },
      "source": [
        "Before we can translate a sentence, we need to preprocess it in the same way as we did the training and development sets.\n",
        "\n",
        "We will create the file with our sample text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8fMsFVBSFIg"
      },
      "source": [
        "!echo \"România este un stat situat în sud-estul Europei Centrale, pe cursul inferior al Dunării\" >> data/input.ro\n",
        "!echo \"România a apărut ca stat, condus de Alexandru Ioan Cuza, în 1859.\" >> data/input.ro\n",
        "!echo \"A fost recunoscută ca ţară independentă 19 ani mai târziu.\" >> data/input.ro"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOpD1TMZS9Ex"
      },
      "source": [
        "Preprocessing the input text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKy1DyKeTE-H"
      },
      "source": [
        "# Subword segmentation\n",
        "with open(f'data/input.ro', 'r', encoding='utf8') as in_fh:\n",
        "    sp_out = sp.encode([line.strip() for line in in_fh], out_type=str)\n",
        "with open(f'data/sentpiece-input.ro', 'w', encoding='utf8') as out_fh:\n",
        "    out_fh.writelines([' '.join(line) + '\\n' for line in sp_out])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qwr6t7TN7l"
      },
      "source": [
        "Now we can translate it. To get a readable sentence, we also need to reverse SentencePiece splitting afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uukbfGoFTOru",
        "outputId": "81ce1d6e-6cbe-4be7-8674-dbaeda729240"
      },
      "source": [
        "!cat data/sentpiece-input.ro | fairseq-interactive data/bin-data \\\n",
        "                                               --source-lang ro \\\n",
        "                                               --target-lang en \\\n",
        "                                               --path data/et2en_model/checkpoint_best.pt \\\n",
        "                                               > data/output.en"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVz9flaNThl6",
        "outputId": "3473e512-213b-403d-f98f-a2a7748b3540"
      },
      "source": [
        "!cat data/output.en"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-20 20:03:59 | INFO | fairseq_cli.interactive | Namespace(all_gather_list_size=16384, batch_size=1, batch_size_valid=None, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, buffer_size=1, checkpoint_shard_count=1, checkpoint_suffix='', constraints=None, cpu=False, criterion='cross_entropy', curriculum=0, data='data/bin-data', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, lm_path=None, lm_weight=0.0, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer=None, path='data/et2en_model/checkpoint_best.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, scoring='bleu', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='ro', target_lang='en', task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
            "2021-10-20 20:03:59 | INFO | fairseq.tasks.translation | [ro] dictionary: 4088 types\n",
            "2021-10-20 20:03:59 | INFO | fairseq.tasks.translation | [en] dictionary: 4088 types\n",
            "2021-10-20 20:03:59 | INFO | fairseq_cli.interactive | loading model(s) from data/et2en_model/checkpoint_best.pt\n",
            "2021-10-20 20:04:01 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
            "2021-10-20 20:04:01 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n",
            "S-0\t▁România ▁a ▁apă r ut ▁ca ▁stat , ▁condus ▁de ▁A le x and ru ▁I o an ▁Cu z a , ▁în ▁18 5 9 .\n",
            "W-0\t0.300\tseconds\n",
            "H-0\t-2.1851954460144043\t▁Romania ▁in ▁Romania , ▁Romania , ▁Greece , ▁I ▁am ▁a x i g an c tion ▁of ▁the ▁E x an c tion ▁of ▁the ▁E x i tion ▁of ▁the ▁19 9 5 9 5 9 9 9 9 9 9 9 9 9 9 9 .\n",
            "D-0\t-2.1851954460144043\t▁Romania ▁in ▁Romania , ▁Romania , ▁Greece , ▁I ▁am ▁a x i g an c tion ▁of ▁the ▁E x an c tion ▁of ▁the ▁E x i tion ▁of ▁the ▁19 9 5 9 5 9 9 9 9 9 9 9 9 9 9 9 .\n",
            "P-0\t-2.0201 -3.8609 -0.8894 -0.8900 -2.6395 -1.0702 -3.8634 -0.9405 -3.4683 -1.9833 -4.2430 -2.1851 -2.9252 -4.0996 -3.1004 -3.9013 -2.5738 -2.3000 -0.9514 -4.7718 -1.3671 -3.2257 -3.0224 -2.0490 -1.4936 -1.0457 -5.4170 -1.7744 -3.4432 -3.2102 -1.7735 -1.2846 -4.8084 -0.4038 -1.7350 -0.6109 -1.9103 -0.6757 -1.4090 -1.3802 -1.4019 -1.4567 -1.5171 -1.5585 -1.5746 -1.6060 -1.6687 -1.7560 -1.9865 -0.0168\n",
            "S-1\t▁România ▁a ▁apă r ut ▁ca ▁stat , ▁condus ▁de ▁A le x and ru ▁I o an ▁Cu z a , ▁în ▁18 5 9 .\n",
            "W-1\t0.291\tseconds\n",
            "H-1\t-2.1851954460144043\t▁Romania ▁in ▁Romania , ▁Romania , ▁Greece , ▁I ▁am ▁a x i g an c tion ▁of ▁the ▁E x an c tion ▁of ▁the ▁E x i tion ▁of ▁the ▁19 9 5 9 5 9 9 9 9 9 9 9 9 9 9 9 .\n",
            "D-1\t-2.1851954460144043\t▁Romania ▁in ▁Romania , ▁Romania , ▁Greece , ▁I ▁am ▁a x i g an c tion ▁of ▁the ▁E x an c tion ▁of ▁the ▁E x i tion ▁of ▁the ▁19 9 5 9 5 9 9 9 9 9 9 9 9 9 9 9 .\n",
            "P-1\t-2.0201 -3.8609 -0.8894 -0.8900 -2.6395 -1.0702 -3.8634 -0.9405 -3.4683 -1.9833 -4.2430 -2.1851 -2.9252 -4.0996 -3.1004 -3.9013 -2.5738 -2.3000 -0.9514 -4.7718 -1.3671 -3.2257 -3.0224 -2.0490 -1.4936 -1.0457 -5.4170 -1.7744 -3.4432 -3.2102 -1.7735 -1.2846 -4.8084 -0.4038 -1.7350 -0.6109 -1.9103 -0.6757 -1.4090 -1.3802 -1.4019 -1.4567 -1.5171 -1.5585 -1.5746 -1.6060 -1.6687 -1.7560 -1.9865 -0.0168\n",
            "S-2\t▁A ▁fost ▁re cunoscut ă ▁ca ▁ţară ▁independent ă ▁19 ▁ani ▁mai ▁târziu .\n",
            "W-2\t0.075\tseconds\n",
            "H-2\t-1.4470196962356567\t▁The ▁country ▁has ▁been ▁condemn ed ▁in ▁19 9 ▁years .\n",
            "D-2\t-1.4470196962356567\t▁The ▁country ▁has ▁been ▁condemn ed ▁in ▁19 9 ▁years .\n",
            "P-2\t-1.7160 -0.2276 -1.8855 -0.6327 -4.8438 -0.0727 -3.7652 -1.3527 -1.4087 -1.2907 -0.1641 -0.0045\n",
            "2021-10-20 20:04:02 | INFO | fairseq_cli.interactive | Total time: 3.031 seconds; translation time: 0.666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXgLsvXuTzAo"
      },
      "source": [
        "!grep \"^H\" data/output.en | cut -f3 > data/hypothesis.en"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGRGCBNHT2Wv",
        "outputId": "f08066e5-ce2a-470f-e300-2bbfb0f4d085"
      },
      "source": [
        "# De-SentencePiece\n",
        "with open(f'data/hypothesis.en', 'r', encoding='utf8') as in_fh:\n",
        "    de_sp_out = [sp.decode(line.strip().split()) for line in in_fh]\n",
        "    print(de_sp_out)\n",
        "with open(f'data/de-sentpiece-hypothesis.en', 'w', encoding='utf8') as out_fh:\n",
        "    out_fh.writelines([line + '\\n' for line in de_sp_out])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.', 'Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.', 'The country has been condemned in 199 years.', 'Romania is a whole of the Easter of Central Central Central Central Central Central Central Central Central Central Central Central Central Bank.', 'Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.', 'The country has been condemned in 199 years.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4UHuXmHUTX9",
        "outputId": "08dd3ba3-b969-4b9e-cc1b-427d12947f20"
      },
      "source": [
        "!cat data/de-sentpiece-hypothesis.en"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.\n",
            "Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.\n",
            "The country has been condemned in 199 years.\n",
            "Romania is a whole of the Easter of Central Central Central Central Central Central Central Central Central Central Central Central Central Bank.\n",
            "Romania in Romania, Romania, Greece, I am axiganction of the Exanction of the Exition of the 19959599999999999.\n",
            "The country has been condemned in 199 years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i4X8gLyUpI8"
      },
      "source": [
        "You can probably see that our model generates readable English text, but it is not necessarily a translation of the input. The language model component is already OK, but the conditioning part is not working yet. You will fix it when you train a bigger baseline with more data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCKEFWZNUqEl"
      },
      "source": [
        "##Assignment\n",
        "\n",
        "To be uploaded here: https://forms.gle/A8rHbckQcfZfRMJMA\n",
        "\n",
        "Try to experiment with other framework(s) for machine translation. You can use the list of resources from the begging of the lab or any other framework you know for NMT.\n",
        "\n",
        "You can use [Europarl data](https://www.statmt.org/europarl/) or experiment with other data from  https://www.statmt.org/.\n",
        "\n",
        "Split the data you are using into train/dev/test and report your performance in terms on BLEU score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i-7NVX5voqm"
      },
      "source": [
        "###Resources\n",
        "\n",
        "* [Intro to Pytorch](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)\n",
        "* [Pytorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)\n",
        "* [Intro to Tensorflow](https://github.com/udacity/intro-to-ml-tensorflow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU4Ag2uJ-GDr"
      },
      "source": [
        "Notebook adapted from: [MTAT.06.055 Machine Translation](https://courses.cs.ut.ee/2021/mt/spring/Main/HomePage)"
      ]
    }
  ]
}