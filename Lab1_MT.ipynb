{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1-MT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkR2f7e+5s4IGnj6waYpCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bucuram/machine-translation-labs/blob/main/Lab1_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pRK9Twi7hDL"
      },
      "source": [
        "#Manual and Automatic Evaluation of Machine Translation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Dqpyor-OHp"
      },
      "source": [
        "We will use the [europarl parallel corpus](http://www.statmt.org/europarl/) from the [WMT16](http://www.statmt.org/wmt16/translation-task.html#download).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4wYJt6YHhU"
      },
      "source": [
        "##Manual Evaluation\n",
        "\n",
        "**Adequacy** - how much of the meaning expressed in the gold-standard translation or source is also expressed in the target translation. The annotators must be bilingual in both the **source** and **target** language in order to judge whether the information is preserved across translation.\n",
        "\n",
        "**Fluency** - refers to the **target** only, without taking the source into account; criteria are grammar, spelling, choice of words, and style.\n",
        "\n",
        "![manual_eval](https://www.researchgate.net/profile/Linda-Alkhawaja/publication/340974510/figure/tbl1/AS:885277719535620@1588078064880/Numeric-scale-for-judging-adequacy-and-fluency_W640.jpg)\n",
        "\n",
        "[Photo source](https://www.researchgate.net/publication/340974510_Neural_Machine_Translation_Fine-Grained_Evaluation_of_Google_Translate_Output_for_English-to-Arabic_Translation/figures?lo=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXmgY5Rz5Fpc"
      },
      "source": [
        "Source Text - English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojXKNja55ze2"
      },
      "source": [
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GorFnIqK5WCz"
      },
      "source": [
        "source_text = \"\"\"Brazil's Former Presidential Chief-of-Staff to Stand Trial.\n",
        "    A federal judge on Tuesday accepted the charges filed against Brazil's former presidential chief of staff for his alleged involvement in a massive corruption scheme at state-owned oil company Petrobras.\n",
        "    The federal prosecutor's office said Jose Dirceu will face trial on the corruption, racketeering and money laundering charges filed earlier this month.\n",
        "    Fourteen other people will also be tried, including Joao Vaccari Neto, the former treasurer of Brazil's governing Workers' Party and Renato de Souza Duque, Petrobras' former head of corporate services.\"\"\"\n",
        "pprint(source_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zenyWLql5iUt"
      },
      "source": [
        "Target Text - Romanian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn-hXj_d5u-U"
      },
      "source": [
        "target_text_system_A = \"\"\"Brazilia fostul șef prezidențial-of-Staff pentru a stand trial.\n",
        "    Un judecător federal a acceptat marți acuzațiile formulate împotriva fostului șef de cabinet prezidențial al Braziliei pentru presupusa sa implicare într-o schemă masivă de corupție la compania petrolieră de stat Petrobras.\n",
        "    Procuratura federală a declarat că Jose Dirceu va fi judecat pentru acuzațiile de corupție, racketeering și spălare de bani depuse la începutul acestei luni.\n",
        "    Paisprezece alte persoane vor fi, de asemenea, judecate, inclusiv Joao Vaccari Neto, fostul trezorier al Partidului Muncitorilor din Brazilia de guvernământ și Renato de Souza Duque, petrobras fostul șef al serviciilor corporative.\"\"\"\n",
        "pprint(target_text_system_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abYaXAm76Mj5"
      },
      "source": [
        "target_text_system_B = \"\"\"Fostul șef de stat major prezidențial al Braziliei va fi supus procesului.\n",
        "    Un judecător federal a acceptat marți acuzațiile depuse împotriva fostului șef de cabinet prezidențial al Braziliei pentru presupusa sa implicare într-un plan masiv de corupție la compania petrolieră de stat Petrobras.\n",
        "    Procuratura federală a declarat că Jose Dirceu va fi judecat cu privire la acuzațiile de corupție, racket și spălare de bani depuse la începutul acestei luni.\n",
        "    Vor fi judecați și alte paisprezece persoane, printre care Joao Vaccari Neto, fostul trezorier al Partidului Muncitorilor din guvernul Braziliei și Renato de Souza Duque, fostul șef al serviciilor corporative al Petrobras.\"\"\"\n",
        "pprint(target_text_system_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNtzVJHb7IQs"
      },
      "source": [
        "Gold text - Romanian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxP7pZsO7KsH"
      },
      "source": [
        "gold_text = \"\"\"Fostul șef al cabinetului prezidențial brazilian este adus în fața instanței.\n",
        "    Marți, un judecător federal a acceptat acuzațiile aduse împotriva fostului șef al cabinetului prezidențial brazilian pentru presupusa implicare a acestuia într-o schemă masivă de corupție privind compania petrolieră de stat Petrobras.\n",
        "    Biroul procurorului federal a declarat că Jose Dirceu va fi trimis în judecată pentru acuzațiile de corupție, înșelătorie și spălare de bani aduse în această lună.\n",
        "    Alte paisprezece persoane vor fi judecate, printre acestea numărându-se Joao Vaccari Neto, fostul trezorier al Partidului Muncitorilor, aflat la putere în Brazilia, și Renato de Souza Duque, fostul președinte al serviciilor pentru întreprinderi ale Petrobras.\"\"\"\n",
        "pprint(gold_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzxgLPbJxRPS"
      },
      "source": [
        "##Automatic evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DsrYY9N_D2Y"
      },
      "source": [
        "Preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snxz3RztBylk"
      },
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ_SKl9EfKWD"
      },
      "source": [
        "!python -m spacy download ro_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4dhds9LBC1c"
      },
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "\n",
        "nlp = spacy.load('ro_core_news_sm')\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text.strip() for sent in doc.sents]\n",
        "    tokenized_text = []\n",
        "    for sent in sentences:\n",
        "        sent = [tok.text for tok in nlp.tokenizer(sent) if tok.text not in string.punctuation]\n",
        "        tokenized_text.append(sent)\n",
        "    return tokenized_text\n",
        "\n",
        "tokenized_source = tokenize(source_text)\n",
        "tokenized_system_A = tokenize(target_text_system_A)\n",
        "tokenized_system_B = tokenize(target_text_system_B)\n",
        "tokenized_gold = tokenize(gold_text)\n",
        "print(tokenized_system_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r02STaQsXOfr"
      },
      "source": [
        "###Precision, Recall, F1\n",
        "\n",
        "![prec1](https://i.imgur.com/OIwtGu2.png)\n",
        "\n",
        "![prec2](https://i.imgur.com/tfLDjl1.png)\n",
        "\n",
        "[Photo source](http://www.statmt.org/book/slides/08-evaluation.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYJRC8BlkHK6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb4C4UbrkH1f"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def precision_recall_f1(ref, hypo):\n",
        "    prec_sent = []\n",
        "    recall_sent = []\n",
        "    f1_sent = []\n",
        "    for r, h in zip(ref, hypo):\n",
        "        prec = len(list(set(r) & set(h))) / len(h)\n",
        "        recall = len(list(set(r) & set(h))) / len(r)\n",
        "        f1 = (prec*recall) / ((prec+recall)/2)\n",
        "\n",
        "        prec_sent.append(prec)\n",
        "        recall_sent.append(recall)\n",
        "        f1_sent.append(f1)\n",
        "\n",
        "    return np.array(prec_sent).mean(), np.array(recall_sent).mean(), np.array(f1_sent).mean()\n",
        "\n",
        "precision, recall, f1 = precision_recall_f1(tokenized_gold, tokenized_system_A)\n",
        "print('System A')\n",
        "print('Precision', precision)\n",
        "print('Recall', recall)\n",
        "print('F1', f1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrGgVwLzzg0o"
      },
      "source": [
        "precision, recall, f1 = precision_recall_f1(tokenized_gold, tokenized_system_B)\n",
        "print('System B')\n",
        "print('Precision', precision)\n",
        "print('Recall', recall)\n",
        "print('F1', f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBi148j5aNN4"
      },
      "source": [
        "##BLEU score\n",
        "\n",
        "![bleu](https://i.imgur.com/jNuIb6k.png)\n",
        "\n",
        "[Photo source](http://www.statmt.org/book/slides/08-evaluation.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aCmIolyx268"
      },
      "source": [
        "BLEU score from [BLEU: a Method for Automatic Evaluation of Machine Translation](https://aclanthology.org/P02-1040.pdf)\n",
        "\n",
        "BLEU score using [nltk.translate.bleu_score](https://www.nltk.org/_modules/nltk/translate/bleu_score.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Kk4kYPsTew"
      },
      "source": [
        "tokenized_gold_bleu = [[sent] for sent in tokenized_gold]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwXuaDI_Btd"
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "nltk_bleu_A = corpus_bleu(tokenized_gold_bleu, tokenized_system_A, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "print('System A')\n",
        "print('BLEU', nltk_bleu_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDcEglOG_iXx"
      },
      "source": [
        "nltk_bleu_B = corpus_bleu(tokenized_gold_bleu, tokenized_system_B, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "print('System B')\n",
        "print('BLEU', nltk_bleu_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLt75n7cUks2"
      },
      "source": [
        "BLEU score using [torchtext.data.metrics](https://pytorch.org/text/stable/data_metrics.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8DJa1tfo6lb"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "torch_bleu_A = bleu_score(tokenized_system_A, tokenized_gold_bleu)\n",
        "print('System A')\n",
        "print('BLEU', torch_bleu_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64SiXNWaA-9-"
      },
      "source": [
        "torch_bleu_B = bleu_score(tokenized_system_B, tokenized_gold_bleu)\n",
        "print('System B')\n",
        "print('BLEU', torch_bleu_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZxDc2hYcbNX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLF5zBbqaZns"
      },
      "source": [
        "### Other Machine Translation metrics\n",
        "\n",
        "* [sacreBLEU](https://github.com/mjpost/sacrebleu)\n",
        "* [chrF](https://github.com/m-popovic/chrF)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waU6n8Mtb2rO"
      },
      "source": [
        "##Assignment\n",
        "\n",
        "**To be uploaded here**: https://forms.gle/T2f2keKN6SWyw1J5A\n",
        "\n",
        "###Data\n",
        "\n",
        "Data from [WMT20](http://www.statmt.org/wmt20/)\n",
        "\n",
        "Download data from [here](https://drive.google.com/drive/folders/1n_alr6WFQZfw4dcAmyxow4V8FC67XD8p)\n",
        "\n",
        "WMT20_data > data-generation-scripts > wmt20-submitted-data.tgz > wmt20-news-task-primary-submissions > txt\n",
        "\n",
        "We have sources, refereces and system outputs.\n",
        "\n",
        "###Requirements\n",
        "\n",
        "* Use data from WMT20 and choose a language for which you will compute automated evaluation metrics and rank the system outputs.\n",
        "\n",
        "* You can use Precision, Recall, F1, BLEU or other automated measure.\n",
        "\n",
        "###Important\n",
        "\n",
        "* Using google colab for this assignment is not mandatory, you can send an archive with your code.\n",
        "\n",
        "\n",
        "[Description of the systems](http://www.statmt.org/wmt20/program.html)\n",
        "\n",
        "[WMT20 Paper](http://www.statmt.org/wmt20/pdf/2020.wmt-1.1.pdf)\n",
        "\n",
        "[Official Ranking](http://wmt.ufal.cz/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZDNW2gmGyhl"
      },
      "source": [
        "###Further reading\n",
        "* [Continuous Measurement Scales in\n",
        "Human Evaluation of Machine Translation](https://aclanthology.org/W13-2305.pdf)\n",
        "* [Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine\n",
        "Translation Evaluation Metrics](https://arxiv.org/pdf/2006.06264.pdf)"
      ]
    }
  ]
}